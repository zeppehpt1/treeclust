{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from analysis import label_tools as lt\n",
    "from analysis import prepare\n",
    "from analysis import visualization\n",
    "from analysis import preprocessing\n",
    "from analysis import features as ft\n",
    "from analysis import cluster\n",
    "from analysis import evaluation\n",
    "\n",
    "from analysis.constants import RANDOM_SEEDS\n",
    "\n",
    "importlib.reload(ft)\n",
    "importlib.reload(prepare)\n",
    "\n",
    "random.seed(698)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stadtwald\n",
    "site_folder = '/home/richard/data/Bamberg_Stadtwald/test/'\n",
    "orthophoto_dir = site_folder + 'gt_orthos/'\n",
    "gt_mask_dir = site_folder + 'gt_masks/' # from gt species labels\n",
    "prediction_dir = site_folder + 'predictions/pred_crown_tiles/' # predicted crowns\n",
    "\n",
    "# define folders\n",
    "encoding_dir = Path(site_folder + 'encodings')\n",
    "label_encoding_dir = Path(site_folder + 'label_encodings')\n",
    "result_dir = Path(site_folder + 'results')\n",
    "Path(encoding_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(label_encoding_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(result_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "assert Path(site_folder).exists()\n",
    "assert Path(orthophoto_dir).exists()\n",
    "assert Path(gt_mask_dir).exists()\n",
    "assert Path(prediction_dir).exists()\n",
    "assert Path(encoding_dir).exists()\n",
    "assert Path(label_encoding_dir).exists()\n",
    "assert Path(result_dir).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. extract single tree crowns (polygons) from orthophoto\n",
    "if not Path(site_folder + 'pred_polygon_clipped_raster_files').exists():\n",
    "    prepare.clip_crown_sets_with_gt_masks(orthophoto_dir, prediction_dir, gt_mask_dir, make_squares=False, step_size=0.5)\n",
    "else:\n",
    "    print(\"Cropped files already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. preprocess images create two sets\n",
    "second_set = preprocessing.preprocess_images(site_folder + 'pred_polygon_clipped_raster_files', None, None, False, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature extraction\n",
    "second_set = '/home/richard/data/Bamberg_Stadtwald/test/preprocessed1_None_clahe_clipped_pred_polygon_311/' # smaller amount of images\n",
    "\n",
    "cnns = ['resnet']\n",
    "encoding_files = sorted(encoding_dir.glob('*.pickle'))\n",
    "if len(encoding_files) != 1:\n",
    "    clahe = ft.create_and_save_le_encodings(cnns[0], second_set, site_folder)\n",
    "else:\n",
    "    print(\"Encodings already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Analysis\n",
    "fc1_path = Path('/home/richard/data/Bamberg_Stadtwald/test/encodings/lower_sample/resnet_clahe_polygon_pred.pickle')\n",
    "le_path = Path('/home/richard/data/Bamberg_Stadtwald/test/label_encodings/lower_sample/resnet_clahe_label_encodings.pickle')\n",
    "assert fc1_path.is_file()\n",
    "assert le_path.is_file()\n",
    "with open(fc1_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open(le_path, 'rb') as l:\n",
    "    le = pickle.load(l)\n",
    "files = data['filename']\n",
    "fc1 = data['features']\n",
    "labels = data['labels']\n",
    "y_gt = le.transform(labels)\n",
    "\n",
    "micro_f1_scores = []\n",
    "macro_f1_scores = []\n",
    "weighted_f1_scores = []\n",
    "pred_species = []\n",
    "for seed in tqdm(RANDOM_SEEDS): # 5\n",
    "    reduced = cluster.umap(fc1, seed)\n",
    "    y_pred, micro_f1_score, macro_f1_score, weighted_f1_score, f_star, cohen_kappa, mcc, nmi, num_pred_species = cluster.optics(reduced, y_gt, seed)\n",
    "    micro_f1_scores.append(micro_f1_score)\n",
    "    macro_f1_scores.append(macro_f1_score)\n",
    "    weighted_f1_scores.append(weighted_f1_score)\n",
    "    pred_species.append(num_pred_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(micro_f1_scores), '\\n', np.mean(macro_f1_scores), '\\n', np.mean(weighted_f1_scores))\n",
    "print(round(np.mean(pred_species)))\n",
    "# lower random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(micro_f1_scores), '\\n', np.mean(macro_f1_scores), '\\n', np.mean(weighted_f1_scores))\n",
    "print(round(np.mean(pred_species)))\n",
    "# large sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy random sample of 311 files\n",
    "source = '/home/richard/data/Bamberg_Stadtwald/test/preprocessed_None_clahe_clipped_pred_polygon_858/'\n",
    "destination = '/home/richard/data/Bamberg_Stadtwald/test/random_sample/'\n",
    "\n",
    "files = glob.glob(source + '/*.png')\n",
    "no_of_files = 311\n",
    "\n",
    "for file_name in random.sample(files, no_of_files):\n",
    "    shutil.move(os.path.join(source, file_name), destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectree2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
